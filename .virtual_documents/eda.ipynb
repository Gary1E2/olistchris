


!pip install folium


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from folium.plugins import HeatMap
from math import radians, sin, cos, sqrt, atan2

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# set style
sns.set(style='whitegrid', palette='pastel')
pd.set_option('display.max_colwidth', None)


# importing and assigning simplified names
try:
    customers = pd.read_csv("data/olist_customers_dataset.csv")
    orders = pd.read_csv("data/olist_orders_dataset.csv")
    order_items = pd.read_csv("data/olist_order_items_dataset.csv")
    payments = pd.read_csv("data/olist_order_payments_dataset.csv")
    reviews = pd.read_csv("data/olist_order_reviews_dataset.csv")
    products = pd.read_csv("data/olist_products_dataset.csv")
    sellers = pd.read_csv("data/olist_sellers_dataset.csv")
    geolocation = pd.read_csv("data/olist_geolocation_dataset.csv")
    product_translation = pd.read_csv("data/product_category_name_translation.csv")
except FileNotFoundError:
    print("Try to change the file directories/names")





print("customers:")
print(customers.head().to_string())
print("\n-------------------------\norders:")
print(orders.head().to_string())
print("\n-------------------------\norder_items:")
print(order_items.head().to_string())
print("\n-------------------------\npayments:")
print(payments.head().to_string())
print("\n-------------------------\nreviews:")
print(reviews.head().to_string())
print("\n-------------------------\nproducts:")
print(products.head().to_string())
print("\n-------------------------\nsellers:")
print(sellers.head().to_string())
print("\n-------------------------\ngeolocation:")
print(geolocation.head().to_string())
print("\n-------------------------\nproduct_translation:")
print(product_translation.head().to_string())


# get dtypes
print("customers:")
print(customers.info())
print("\n-------------------------\norders:")
print(orders.info())
print("\n-------------------------\norder_items:")
print(order_items.info())
print("\n-------------------------\npayments:")
print(payments.info())
print("\n-------------------------\nreviews:")
print(reviews.info())
print("\n-------------------------\nproducts:")
print(products.info())
print("\n-------------------------\nsellers:")
print(sellers.info())
print("\n-------------------------\ngeolocation:")
print(geolocation.info())
print("\n-------------------------\nproduct_translation:")
print(product_translation.info())


# num cols info
print("customers:")
print(customers.describe().to_string())
print("\n-------------------------\norders:")
print(orders.describe().to_string())
print("\n-------------------------\norder_items:")
print(order_items.describe().to_string())
print("\n-------------------------\npayments:")
print(payments.describe().to_string())
print("\n-------------------------\nreviews:")
print(reviews.describe().to_string())
print("\n-------------------------\nproducts:")
print(products.describe().to_string())
print("\n-------------------------\nsellers:")
print(sellers.describe().to_string())
print("\n-------------------------\ngeolocation:")
print(geolocation.describe().to_string())
print("\n-------------------------\nproduct_translation:")
print(product_translation.describe().to_string())


# full duplicate rows
for name, df_ in zip(
    ['customers', 'orders', 'order_items', 'payments', 'reviews', 'products', 'sellers', 'geolocation'],
    [customers, orders, order_items, payments, reviews, products, sellers, geolocation]):
    print(f"\n{df_.shape[0]}")
    print(f"{name}: {df_.value_counts().sum()} unique rows")
    print(f"{name}: {df_.duplicated().sum()} duplicate rows")
    print(f"{name} null values:")
    print(df_.isnull().sum())


# check duplicate IDs
print(f"\nUnique ids {customers['customer_unique_id'].duplicated().sum()}")
print(f"ids: {customers['customer_id'].duplicated().sum()}")
print(f"order_ids: {orders['order_id'].duplicated().sum()}")        # Should be 0
print(f"product_ids: {products['product_id'].duplicated().sum()}")  # Should be 0
print(f"seller_ids: {sellers['seller_id'].duplicated().sum()}")     # Should be 0






def pair_plotter(df: pd.DataFrame, title: str, figsize: tuple=None):
    """ creates pairplots of datasets
    
    Parameters:
        figsize: plot size
        title: name of dataset
        dataset: dataframe/dataset
    Returns:
        dataset pairplot
    """
    plt.figure(figsize=figsize)
    sns.pairplot(df, kind='reg', plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1, 'color':'cornflowerblue'}}).figure.suptitle(title + " Dataset Pairplot")
    plt.show()


pair_plotter(order_items, "Order_Items", (8, 6))


pair_plotter(payments, "Payments",  (8, 6))


pair_plotter(products, "Products")


pair_plotter(geolocation, "Geolocation", (8, 6))





orders['order_status'].value_counts()


# convert to datetime
orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])

# extract dt features
orders['year'] = orders['order_purchase_timestamp'].dt.year
orders['month'] = orders['order_purchase_timestamp'].dt.month
orders['weekday'] = orders['order_purchase_timestamp'].dt.day_name()
orders['hour'] = orders['order_purchase_timestamp'].dt.hour


# categorize time of day
def get_part_of_day(hour):
    """ Creates time of day categories from hour """
    if 5 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 17:
        return 'Afternoon'
    elif 17 <= hour < 21:
        return 'Evening'
    else:
        return 'Night'

orders['part_of_day'] = orders['hour'].apply(get_part_of_day)


sns.set_theme(style="whitegrid", palette="hls")
plt.figure(figsize=(18, 14))

# 1. monthly order trend over the years
monthly_orders = orders.groupby(['year', 'month']).size().reset_index(name='order_count')
monthly_orders['year_month'] = pd.to_datetime(monthly_orders[['year', 'month']].assign(day=1))

plt.subplot(311)
sns.lineplot(data=monthly_orders, x='year_month', y='order_count', marker='o')
plt.title('Monthly Order Trend Over Years', fontsize=16)
plt.xlabel('Date', fontsize=16)
plt.ylabel('Number of Orders')
plt.xticks(monthly_orders['year_month'], rotation=45)

# 2. orders by day of week
weekday_order = orders['weekday'].value_counts().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

plt.subplot(312)
sns.barplot(x=weekday_order.index, y=weekday_order.values, palette="hls", hue=weekday_order.index, legend=False)
plt.ylim(0)
plt.title('Orders by Day of the Week', fontsize=16)
plt.xlabel('Weekday', fontsize=16)
plt.ylabel('Number of Orders')
plt.xticks()

# 3. orders by time of Day
plt.subplot(313)
part_of_day_order = orders['part_of_day'].value_counts().reindex(['Morning', 'Afternoon', 'Evening', 'Night'])
sns.barplot(x=part_of_day_order.index, y=part_of_day_order.values, palette="hls", hue=part_of_day_order.index, legend=False)
plt.ylim(0)
plt.title('Orders by Time of Day', fontsize=16)
plt.xlabel('Part of Day', fontsize=16)
plt.ylabel('Number of Orders')

plt.tight_layout()
plt.show()


# create map centered around Brazil
brazil_center = [-14.2350, -51.9253]
m = folium.Map(location=brazil_center, zoom_start=4)

# prepare data for heatmap and add to layer
heat_data = geolocation[['geolocation_lat', 'geolocation_lng']].dropna().values.tolist()

HeatMap(heat_data, radius=8, blur=12, max_zoom=10).add_to(m)

m # plot


# counts by customer's city and state
city_state_counts = customers.groupby(['customer_city', 'customer_state'])['customer_id'].count().reset_index()
city_state_counts.rename(columns={'customer_id': 'order_count'}, inplace=True)
print(city_state_counts.head())
print("\n---------------------\nAmount of cities:", city_state_counts['customer_city'].nunique())
print("Amount of state:", city_state_counts['customer_state'].nunique())


top_cities = city_state_counts.sort_values(by=['order_count'], ascending=False).head(20)

# city: text | state: colour/hue
plt.figure(figsize=(15, 8))
sns.barplot(x='order_count', y='customer_city', hue='customer_state', data=top_cities, palette='hls')
plt.title('Top 20 Cities by Order Count (Customers Data)', fontsize=16)
plt.xlabel('Order Count')
plt.ylabel('City')
plt.legend(title='State', loc='lower right')
plt.tight_layout()
plt.show()





orders_delivered = orders[orders['order_status'] == 'delivered']
orders_delivered = orders_delivered.dropna()
orders_delivered['order_delivered_customer_date'] = pd.to_datetime(orders_delivered['order_delivered_customer_date'])

df = pd.merge(orders_delivered, order_items, on='order_id')
df = pd.merge(df, payments, on='order_id')
df = pd.merge(df, reviews, on='order_id')
df = pd.merge(df, products, on='product_id')

df = pd.merge(df, customers, on='customer_id')

# count unique orders per customer from orders_delivered
order_counts = df.groupby('customer_unique_id')['order_id'].nunique().reset_index(name='order_count')

df = df.drop(['order_id', 'order_status', 'order_approved_at', 'order_delivered_carrier_date', 'order_estimated_delivery_date',
              'order_item_id', 'seller_id', 'review_id', 'review_comment_title', 'payment_sequential', 'product_id',
              'product_name_lenght', 'product_description_lenght', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp'], axis=1)

geo_clean = geolocation.groupby('geolocation_zip_code_prefix')[['geolocation_lat', 'geolocation_lng']].mean()

df = pd.merge(df, geo_clean, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')

df = df.drop(['customer_zip_code_prefix', 'customer_id'], axis=1)

print(df.info())





# using brazil (southern hemisphere), get seasons
def month_to_season(month):
    """ Create time of year categories from month """
    if month in [12, 1, 2]:
        return 'Summer'
    elif month in [3, 4, 5]:
        return 'Autumn'
    elif month in [6, 7, 8]:
        return 'Winter'
    else:  # [9, 10, 11]
        return 'Spring'

df['season'] = df['month'].apply(month_to_season)

# get last purchase date per customer
last_purchase = df.groupby('customer_unique_id')['order_purchase_timestamp'].max().reset_index(name='last_purchase_date')

# get latest date in entire dataset
max_date = df['order_purchase_timestamp'].max()

# get months inactive
last_purchase['months_inactive'] = ((max_date - last_purchase['last_purchase_date']) / pd.Timedelta(days=30)).round().astype(int)

# get delivery time
df['delivery_time'] = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.days

# merge and drop cols
distinct_products_per_customer = df.groupby('customer_unique_id')['product_category_name'].nunique().reset_index(name='distinct_product_categories')
df = df.drop(['order_purchase_timestamp', 'order_delivered_customer_date', 'month', 'year', 'part_of_day'], axis=1)
print(df.info())





# picking most common value (mode) in cat cols
# if multiple equally common values, get the first one.
# if empty, return None
agg_df = df.groupby('customer_unique_id').agg({
    'weekday': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'hour': 'median',
    'price': ['sum', 'mean'],
    'freight_value': 'mean',
    'payment_type': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'payment_installments': 'mean',
    'payment_value': ['sum', 'mean'],
    'review_score': 'mean',
    'product_category_name': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'product_photos_qty': 'mean',
    'product_weight_g': 'mean',
    'product_length_cm': 'mean',
    'product_height_cm': 'mean',
    'product_width_cm': 'mean',
    'customer_city': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'customer_state': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'geolocation_lat': 'mean',
    'geolocation_lng': 'mean',
    'season': lambda x: x.mode().iloc[0] if not x.mode().empty else None,
    'delivery_time': 'mean'
}).reset_index()



# flatten multi index columns
agg_df.columns = ['_'.join(col).strip('_') if isinstance(col, tuple) else col for col in agg_df.columns]

# translating product name to english
agg_df = pd.merge(agg_df, product_translation, left_on='product_category_name_<lambda>', right_on='product_category_name', how='left')
agg_df = agg_df.drop(['product_category_name', 'product_category_name_<lambda>'], axis=1) # Drop the redundant Portuguese column after merging

# merge engineered features
agg_df = pd.merge(agg_df, order_counts, on='customer_unique_id', how='left')

# define repeat buyer
agg_df['repeat_buyer'] = agg_df['order_count'].apply(lambda x: 1 if x > 1 else 0)
agg_df = pd.merge(agg_df, distinct_products_per_customer, on='customer_unique_id')
agg_df = pd.merge(agg_df, last_purchase[['customer_unique_id', 'months_inactive']], on='customer_unique_id', how='left')


print(agg_df.head().to_string())


print(agg_df['payment_type_<lambda>'].value_counts())
print(agg_df['season_<lambda>'].value_counts())
print(agg_df['distinct_product_categories'].value_counts())


print(agg_df.info())





# reduce geolocation to one latitude/longitude per zip code prefix
# (take average of all points sharing same prefix)
geo_prefix = geolocation.groupby('geolocation_zip_code_prefix').agg({
    'geolocation_lat': 'mean',   # average latitude
    'geolocation_lng': 'mean'    # average longitude
}).reset_index()

# merge averaged coords into customers df
customers_loc = (
    customers
    .merge(
        geo_prefix,
        left_on='customer_zip_code_prefix',         # match customer prefix
        right_on='geolocation_zip_code_prefix',     # to averaged geolocation
        how='left'                                  # keep all customers
    )
    .rename(columns={
        'geolocation_lat': 'customer_lat',
        'geolocation_lng': 'customer_lng'
    })
    .drop('geolocation_zip_code_prefix', axis=1)  # drop redundant column
)

# merge averaged coords into sellers df
sellers_loc = (
    sellers
    .merge(
        geo_prefix,
        left_on='seller_zip_code_prefix',
        right_on='geolocation_zip_code_prefix',
        how='left'
    )
    .rename(columns={
        'geolocation_lat': 'seller_lat',
        'geolocation_lng': 'seller_lng'
    })
    .drop('geolocation_zip_code_prefix', axis=1)
)

# build one dataframe linking orders to customers to sellers
order_merged = (
    orders[['order_id', 'customer_id']]                     # start with orders and customer IDs
    .merge(
        customers[['customer_id', 'customer_unique_id']],   # attach customer_unique_id from customers df
        on='customer_id'
    )
    .merge(
        order_items[['order_id', 'seller_id']],             # attach seller IDs via order_items df
        on='order_id'
    )
    .merge(
        customers_loc[['customer_id', 'customer_lat', 'customer_lng']],
        on='customer_id',                                   # attach customer coords
        how='left'
    )
    .merge(
        sellers_loc[['seller_id', 'seller_lat', 'seller_lng']],
        on='seller_id',                                     # attach seller coords
        how='left'
    )
)


# calculate distances on round earth surface using lattitude + longitude: Haversine forumla
def haversine(lat1, lon1, lat2, lon2):
    """ Get great circle distance using Haversine Formula

    Parameters:
        lat1: customer lattitude
        lon1: customer longitude
        lat2: seller lattitude
        lon2: seller longitude
    Returns:
        distance in km
    """
    R = 6371.0  # Earth’s radius in km

    # convert degrees → radians
    phi1, phi2 = radians(lat1), radians(lat2)
    dphi = radians(lat2 - lat1)
    dlambda = radians(lon2 - lon1)

    # Haversine calculation
    a = sin(dphi / 2)**2 + cos(phi1) * cos(phi2) * sin(dlambda / 2)**2
    return 2 * R * atan2(sqrt(a), sqrt(1 - a))

order_merged['distance_km'] = order_merged.apply(
    lambda row: haversine(
        row['customer_lat'], row['customer_lng'],
        row['seller_lat'],   row['seller_lng']
    )
    if pd.notnull(row['customer_lat']) and pd.notnull(row['seller_lat'])
    else None,  # skip if any coordinate is missing
    axis=1
)

order_merged.head()


# agg avg distance per customer
avg_distance_per_customer = (
    order_merged
    .groupby('customer_unique_id')['distance_km']
    .mean()
    .reset_index()
    .rename(columns={'distance_km': 'avg_distance_km'})
)

# merge back into agg_df
agg_df = pd.merge(agg_df, avg_distance_per_customer, on='customer_unique_id', how='left')


print(agg_df.head().to_string())


print(agg_df.info())


print(agg_df[['product_length_cm_mean', 'product_height_cm_mean', 'product_width_cm_mean', 'product_weight_g_mean']].describe().to_string())


# creating volume mean for models
agg_df['volume_mean'] = agg_df['product_length_cm_mean'] * agg_df['product_width_cm_mean'] * agg_df['product_height_cm_mean']
print(agg_df[['volume_mean', 'product_length_cm_mean', 'product_width_cm_mean', 'product_height_cm_mean']].head().to_string())


# replace 0g weights to 0.1g weights to avoid division by zero error
agg_df['product_weight_g_mean'] = agg_df['product_weight_g_mean'].replace(0, 0.1)

agg_df['cost_volume'] = agg_df['price_mean'] / agg_df['volume_mean']
agg_df['density_mean'] = agg_df['product_weight_g_mean'] / agg_df['volume_mean']
agg_df['cost_weight'] = agg_df['price_mean'] / agg_df['product_weight_g_mean']
agg_df['lh_ratio'] = agg_df['product_length_cm_mean'] / agg_df['product_height_cm_mean']
agg_df['lw_ratio'] = agg_df['product_length_cm_mean'] / agg_df['product_width_cm_mean']
agg_df['hw_ratio'] = agg_df['product_height_cm_mean'] / agg_df['product_width_cm_mean']

print(agg_df[['cost_volume', 'density_mean', 'cost_weight', 'lh_ratio', 'lw_ratio', 'hw_ratio']].head().to_string())


# confirm no duplicates or nulls and drop for modelling
print(agg_df.duplicated().sum())
print(agg_df.isnull().sum().sum())


agg_df.dropna(inplace=True)
print(agg_df.isnull().sum().sum())





agg_df.to_csv('data/olist_final.csv', index=False)





final_df = pd.read_csv('data/olist_final.csv')


print(final_df.shape, '\n--------------------')
print(final_df.head().to_string())





def plot_feature_target_distribution(df: pd.DataFrame, feature: str, target: str):
    """
    Creates grouped bar chart to show percentage distribution of a given feature
    within each repeat_buyer group (Repeat Buyer vs One-time Buyer).

    Parameters:
        feature: column name to analyze
        target: target name
        df: dataframe
    Returns:
        grouped bar graph plot
    """
    if feature not in df.columns:
        raise ValueError(f"'{feature}' not found in the DataFrame.")
    if target not in df.columns:
        raise ValueError(f"'{target}' not found in the DataFrame.")

    # prepare and count
    plot_df = df.groupby([target, feature]).size().reset_index(name='count')
    plot_df[target] = plot_df[target].map({1: 'Repeat Buyer', 0: 'One-time Buyer'})

    # total count per group (repeat vs one-time)
    group_totals = plot_df.groupby(target)['count'].transform('sum')
    plot_df['percentage'] = (plot_df['count'] / group_totals * 100).round(2)

    # sort feature values if numeric
    if pd.api.types.is_numeric_dtype(df[feature]):
        plot_df = plot_df.sort_values(by=feature)

    # Plot
    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(12, 6))
    sns.barplot(
        data=plot_df,
        x=feature,
        y='percentage',
        hue=target,
        palette='Set2'
    )

    plt.title(f'{feature.replace("_", " ").title()} (% within Repeat Buyer Groups)', fontsize=16)
    plt.xlabel(feature.replace("_", " ").title())
    plt.ylabel('Percentage of Customers (%)')
    plt.legend(title='Customer Type')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()


def plot_kde_by_class_target(df: pd.DataFrame, feature: str, target: str, labels: list, clip_upper=None, bandwidth_adjust=1):
    """
    Plots KDE distribution for a num feature, comparing target classes.

    Parameters:
        df: dataframe with feature and target
        feature: numeric column to visualize.
        target: target column
        clip_upper (float, optional): upper limit to clip outliers for cleaner visualization.
        bandwidth_adjust (float, optional): KDE smoothing.
    Returns:
        KDE plot
    """
    if feature not in df.columns or target not in df.columns:
        raise ValueError(f"'{feature}' or '{target}' not found in DataFrame.")

    plot_df = df.copy()

    # optional clipping to handle outliers
    if clip_upper is not None:
        clipped_col = f"{feature}_clipped"
        plot_df[clipped_col] = plot_df[feature].clip(upper=clip_upper)
        num_clipped = (plot_df[feature] > clip_upper).sum()
        print(f"Clipped {num_clipped} values > {clip_upper} in '{feature}'.")
        feature = clipped_col

    plt.figure(figsize=(10, 6))
    sns.kdeplot(
        data=plot_df[plot_df[target] == 0],
        x=feature,
        label=labels[0],
        fill=True,
        color='salmon',
        alpha=0.5,
        bw_adjust=bandwidth_adjust
    )
    sns.kdeplot(
        data=plot_df[plot_df[target] == 1],
        x=feature,
        label=labels[1],
        fill=True,
        color='seagreen',
        alpha=0.5,
        bw_adjust=bandwidth_adjust
    )

    plt.title(f'Distribution of {feature.replace("_", " ").title()}', fontsize=16)
    plt.xlabel(feature.replace("_", " ").title())
    plt.ylabel('Density')
    plt.legend(title='Customer Type')
    plt.tight_layout()
    plt.show()


def plot_boxplot_by_target(df: pd.DataFrame, feature: str, target: str, clip_upper_quantile=0.95):
    """
    Draws a boxplot comparing a categorical feature across buyer types.
    Clipping is applied to reduce the impact of extreme outliers.

    Parameters:
        df: dataframe with feature and target
        feature: numeric column to visualize.
        target: target column
        clip_upper_quantile (float): Quantile to clip the feature at (default is 95th percentile).
    Returns:
        Box Plot
    """
    if feature not in df.columns or target not in df.columns:
        raise ValueError(f"'{feature}' or '{target}' not found in DataFrame.")
        
    df_plot = df.copy()
    
    # determine clipping threshold
    upper_threshold = df_plot[feature].quantile(clip_upper_quantile)
    num_clipped = (df_plot[feature] > upper_threshold).sum()
    df_plot[feature] = df_plot[feature].clip(upper=upper_threshold)

    # print note
    if num_clipped > 0:
        print(f"Note: {num_clipped} values clipped at {clip_upper_quantile*100:.0f}th percentile")

    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(6, 4))
    sns.boxplot(data=df_plot, x=target, y=feature)
    plt.title(f'{feature.replace("_", " ").title()} by {target.replace("_", " ").title()} (Clipped)', fontsize=15)
    plt.xlabel(target.replace("_", " ").title())
    plt.ylabel(feature.replace("_", " ").title())

    plt.tight_layout()
    plt.show()


def plot_histogram_by_feature(df: pd.DataFrame, feature: str, target: str, bins: int=30, clip_upper=None):
    """
    Draws a histograme comparing a categorical feature across buyer types.
    Clipping is applied to reduce the impact of extreme outliers.

    Parameters:
        df: dataframe with feature and target
        feature: numeric column to visualize.
        target: target column
        bins: range of values for a bin to capture
        clip_upper (float, optional): upper limit to clip outliers for cleaner visualization.
    Returns:
        Histogram Plot
    """
    if feature not in df.columns or target not in df.columns:
        raise ValueError(f"'{feature}' or '{target}' not found in DataFrame.")
    
    df_plot = df.copy()
    unique_classes = df_plot[feature].unique()
    palette = sns.color_palette("hls", n_colors=len(unique_classes))
    
    if clip_upper is not None:
        df_plot[feature] = df_plot[feature].clip(upper=clip_upper)

    plt.figure(figsize=(10, 6))
    if len(unique_classes) < 12:
        sns.histplot(data=df_plot, x=target, bins=bins, palette=palette, hue=feature,
                    element='step', stat='density', common_norm=False)
    else:
        print("Too many labels: ", len(unique_classes))
        sns.histplot(data=df_plot, x=target, bins=bins, palette=palette, hue=feature,
                    element='step', stat='density', common_norm=False, legend=False)
    plt.title(f'Histogram of {target.replace("_", " ").title()} by {feature.replace("_", " ").title()}')
    plt.xlabel(feature.replace("_", " ").title())
    plt.ylabel('Density')
    plt.tight_layout()
    plt.show()





repeat_coords = agg_df[agg_df['repeat_buyer'] == 1][['geolocation_lat_mean','geolocation_lng_mean']].dropna().values.tolist()
non_repeat_coords = agg_df[agg_df['repeat_buyer'] == 0][['geolocation_lat_mean','geolocation_lng_mean']].dropna().values.tolist()
standard_coords = agg_df[['geolocation_lat_mean', 'geolocation_lng_mean']].dropna().values.tolist()

m = folium.Map(location=brazil_center, zoom_start=5)

# all buyers
HeatMap(
    standard_coords,
    radius=8,
    blur=12,
    max_zoom=10,
    name='All Buyers'
).add_to(m)

# non-repeat buyers
HeatMap(
    non_repeat_coords,
    radius=8,
    blur=12,
    max_zoom=10,
    name='Non-Repeat Buyers'
).add_to(m)

# repeat buyers
HeatMap(
    repeat_coords,
    radius=8,
    blur=12,
    max_zoom=10,
    name='Repeat Buyers'
).add_to(m)

# adding toggling
folium.LayerControl().add_to(m)

m


plot_feature_target_distribution(final_df, 'season_<lambda>', 'repeat_buyer')
plot_feature_target_distribution(final_df, 'weekday_<lambda>', 'repeat_buyer')
plot_feature_target_distribution(final_df, 'payment_type_<lambda>', 'repeat_buyer')
plot_feature_target_distribution(final_df, 'distinct_product_categories', 'repeat_buyer')
plot_feature_target_distribution(final_df, 'customer_state_<lambda>', 'repeat_buyer')


plot_kde_by_class_target(final_df, 'avg_distance_km', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"], clip_upper=4000)
plot_kde_by_class_target(final_df, 'months_inactive', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"])
plot_kde_by_class_target(final_df, 'hour_median', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"])
plot_kde_by_class_target(final_df, 'review_score_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"])


# Graphs of all the money-related features
plot_kde_by_class_target(final_df, 'price_sum', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"],  clip_upper=2000)
plot_kde_by_class_target(final_df, 'price_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"],  clip_upper=1000)
plot_kde_by_class_target(final_df, 'freight_value_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"],  clip_upper=100)


# Graphs of all the product-related features
plot_kde_by_class_target(final_df, 'product_photos_qty_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"], clip_upper=12.5)
plot_kde_by_class_target(final_df, 'product_weight_g_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"], clip_upper=20000)
plot_kde_by_class_target(final_df, 'product_length_cm_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"])
plot_kde_by_class_target(final_df, 'product_height_cm_mean', 'repeat_buyer', ["One-Time Buyer", "Repeat Buyer"])


plot_boxplot_by_target(final_df, "freight_value_mean", "repeat_buyer")
plot_boxplot_by_target(final_df, "avg_distance_km", "repeat_buyer")
plot_boxplot_by_target(final_df, "months_inactive", "repeat_buyer")
plot_boxplot_by_target(final_df, "hour_median", "repeat_buyer")
plot_boxplot_by_target(final_df, "review_score_mean", "repeat_buyer")


# Graphs of all the money-related features
plot_boxplot_by_target(final_df, "price_sum", "repeat_buyer")
plot_boxplot_by_target(final_df, "price_mean", "repeat_buyer")
plot_boxplot_by_target(final_df, "freight_value_mean", "repeat_buyer")


# Graphs of all the product-related features
plot_boxplot_by_target(final_df, 'product_photos_qty_mean', "repeat_buyer")
plot_boxplot_by_target(final_df, 'product_weight_g_mean', "repeat_buyer")
plot_boxplot_by_target(final_df, 'product_length_cm_mean', "repeat_buyer")
plot_boxplot_by_target(final_df, 'product_height_cm_mean', "repeat_buyer")





print(final_df.columns)


plot_histogram_by_feature(final_df, "weekday_<lambda>", "freight_value_mean")
plot_histogram_by_feature(final_df, "hour_median", "freight_value_mean")
plot_histogram_by_feature(final_df, "season_<lambda>", "freight_value_mean")
plot_histogram_by_feature(final_df, "customer_state_<lambda>", "freight_value_mean")
plot_histogram_by_feature(final_df, "distinct_product_categories", "freight_value_mean")





plot_histogram_by_feature(final_df, "weekday_<lambda>", "delivery_time_mean")
plot_histogram_by_feature(final_df, "hour_median", "delivery_time_mean")
plot_histogram_by_feature(final_df, "season_<lambda>", "delivery_time_mean")
plot_histogram_by_feature(final_df, "customer_state_<lambda>", "delivery_time_mean")
plot_histogram_by_feature(final_df, "distinct_product_categories", "delivery_time_mean")


pair_plotter(final_df[['freight_value_mean', 'product_weight_g_mean', 'product_length_cm_mean',
                        'product_height_cm_mean', 'product_width_cm_mean', 'avg_distance_km', "delivery_time_mean"]],
                        "Final")



